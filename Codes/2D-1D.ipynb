{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2D-1D.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdC++i4griu3KWAYYDYGGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrzResearchArena/Anticancer-Peptides-CNN/blob/master/Codes/2D-1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj8m4wmKno1M"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3bgYBZ-nxxK",
        "outputId": "0ac1e452-6f54-41d3-e027-92dd3c44cbd2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPGOYfY1oLoq",
        "outputId": "da966376-8992-43be-8f83-297c7868d73f"
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEYrb3hWoU3Z",
        "outputId": "17e472f5-370d-4821-bc67-05a73794c8f4"
      },
      "source": [
        "cd 'drive/My Drive/ACP-PyFeat'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ACP-PyFeat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFqd_2adoWl7",
        "outputId": "01c7231a-67b4-42f0-91df-085216d79662"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acp164.txt       blosum-164.npy      bpf-val-194.npy\n",
            "acp240.txt       blosum-240.npy      dataset-details.txt\n",
            "acp500.txt       blosum-500.npy      main-AntiCP.h5\n",
            "acp740.txt       blosum-740.npy      main-train.fa\n",
            "alter-AntiCP.h5  blosum-in-689.npy   main-val-172.fa\n",
            "alt-train.fa     blosum-in-776.npy   model-240.png\n",
            "alt-val-194.fa   blosum-val-172.npy  model-240-single-head.png\n",
            "bit-in-689.npy   blosum-val-194.npy  model-500-164.png\n",
            "bit-in-776.npy   bpf-164.npy         model-740.png\n",
            "bits-164.npy     bpf-240.npy         model-740-single-head.png\n",
            "bits-240.npy     bpf-500.npy         model-single-Head-500-164.png\n",
            "bits-500.npy     bpf-740.npy         ROC-240.png\n",
            "bits-740.npy     bpf-in-689.npy      ROC-500-164.png\n",
            "bit-val-172.npy  bpf-in-776.npy      ROC-740.png\n",
            "bit-val-194.npy  bpf-val-172.npy     ROC.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b09x2KRIoYQ5"
      },
      "source": [
        "d740bpf   = np.load('bpf-740.npy')\n",
        "d740bit   = np.load('bits-740.npy')\n",
        "d740blo62 = np.load('blosum-740.npy')\n",
        "\n",
        "d240bpf   = np.load('bpf-240.npy')\n",
        "d240bit   = np.load('bits-240.npy')\n",
        "d240blo62 = np.load('blosum-240.npy')\n",
        "\n",
        "d500bpf   = np.load('bpf-500.npy')\n",
        "d500bit   = np.load('bits-500.npy')\n",
        "d500blo62 = np.load('blosum-500.npy')\n",
        "\n",
        "d164bpf   = np.load('bpf-164.npy')\n",
        "d164bit   = np.load('bits-164.npy')\n",
        "d164blo62 = np.load('blosum-164.npy')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ-Krsc1pxCN",
        "outputId": "e841f849-af7b-4f13-991a-7180a36da7f6"
      },
      "source": [
        "d740bit.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(740, 25, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLBXiy4zp62w",
        "outputId": "fc2cb67b-9e7e-48bc-f295-74e0ea29238e"
      },
      "source": [
        "print(d740bpf.shape)\n",
        "print(d740bit.shape)\n",
        "print(d740blo62.shape)\n",
        "\n",
        "print(d240bpf.shape)\n",
        "print(d240bit.shape)\n",
        "print(d240blo62.shape)\n",
        "\n",
        "print(d500bpf.shape)\n",
        "print(d500bit.shape)\n",
        "print(d500blo62.shape)\n",
        "\n",
        "print(d164bpf.shape)\n",
        "print(d164bit.shape)\n",
        "print(d164blo62.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(740, 25, 20)\n",
            "(740, 25, 31)\n",
            "(740, 25, 20)\n",
            "(240, 25, 20)\n",
            "(240, 25, 31)\n",
            "(240, 25, 20)\n",
            "(500, 25, 20)\n",
            "(500, 25, 31)\n",
            "(500, 25, 20)\n",
            "(164, 25, 20)\n",
            "(164, 25, 31)\n",
            "(164, 25, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9isNC-amqT2x",
        "outputId": "a304cde7-e11b-47fc-fcc8-77a5232d3380"
      },
      "source": [
        "A = np.array([\n",
        "    [ 1,  2,  3],\n",
        "    [11, 22, 33]\n",
        "])\n",
        "print(A)\n",
        "\n",
        "A = A.flatten()\n",
        "print(A)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3]\n",
            " [11 22 33]]\n",
            "[ 1  2  3 11 22 33]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUs_JkZvrF5z"
      },
      "source": [
        "def convert2D1D(D):\n",
        "    A = []\n",
        "    for d in D:\n",
        "        A.append(d.flatten())\n",
        "    #end-for\n",
        "    return np.array(A)\n",
        "#end-def"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpFfTaYArXJj"
      },
      "source": [
        "d740bpf = convert2D1D(d740bpf)\n",
        "d740bit = convert2D1D(d740bit)\n",
        "d740blo62 = convert2D1D(d740blo62)\n",
        "\n",
        "d240bpf = convert2D1D(d240bpf)\n",
        "d240bit = convert2D1D(d240bit)\n",
        "d240blo62 = convert2D1D(d240blo62)\n",
        "\n",
        "d500bpf = convert2D1D(d500bpf)\n",
        "d500bit = convert2D1D(d500bit)\n",
        "d500blo62 = convert2D1D(d500blo62)\n",
        "\n",
        "d164bpf = convert2D1D(d164bpf)\n",
        "d164bit = convert2D1D(d164bit)\n",
        "d164blo62 = convert2D1D(d164blo62)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFQ6Rcoysucq",
        "outputId": "4923bb8d-363e-4d76-99ac-d90076fad76a"
      },
      "source": [
        "print(d740bpf.shape)\n",
        "print(d740bit.shape)\n",
        "print(d740blo62.shape)\n",
        "\n",
        "print(d240bpf.shape)\n",
        "print(d240bit.shape)\n",
        "print(d240blo62.shape)\n",
        "\n",
        "print(d500bpf.shape)\n",
        "print(d500bit.shape)\n",
        "print(d500blo62.shape)\n",
        "\n",
        "print(d164bpf.shape)\n",
        "print(d164bit.shape)\n",
        "print(d164blo62.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(740, 500)\n",
            "(740, 775)\n",
            "(740, 500)\n",
            "(240, 500)\n",
            "(240, 775)\n",
            "(240, 500)\n",
            "(500, 500)\n",
            "(500, 775)\n",
            "(500, 500)\n",
            "(164, 500)\n",
            "(164, 775)\n",
            "(164, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zqwxrRJvmQz"
      },
      "source": [
        "d740y  = [1 for _ in range(376)]\n",
        "d740y += [0 for _ in range(364)]\n",
        "d740y  = np.array(d740y)\n",
        "\n",
        "\n",
        "d240y  = [1 for _ in range(129)]\n",
        "d240y += [0 for _ in range(111)]\n",
        "d240y  = np.array(d240y)\n",
        "\n",
        "\n",
        "d500ytrain  = [0 for _ in range(250)]\n",
        "d500ytrain += [1 for _ in range(250)]\n",
        "d500ytrain  = np.array(d500ytrain)\n",
        "\n",
        "\n",
        "d164ytest  = [0 for _ in range(82)]\n",
        "d164ytest += [1 for _ in range(82)]\n",
        "d164ytest  = np.array(d164ytest)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elVjRsj4yP5b"
      },
      "source": [
        "# Convert into TF-IDF\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "\n",
        "def TFIDF(D):\n",
        "    tfidf = TfidfTransformer(norm='l2').fit(D)\n",
        "\n",
        "    return np.array(tfidf.transform(D).todense())\n",
        "#end-def"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "940bDhmuIL0Z"
      },
      "source": [
        "b = TFIDF(d740bit)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Bl1JkKIimH",
        "outputId": "a54711ce-c702-4e23-d271-c3b0a25ff4cc"
      },
      "source": [
        "b.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(740, 775)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIF6A_mxJANY",
        "outputId": "1e0f7222-1933-4a02-fe7d-0fccc45fb4c4"
      },
      "source": [
        "b"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.07429004, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.0853151 ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31t8JysZL47j"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import BaggingClassifier, \\\n",
        "     RandomForestClassifier, \\\n",
        "     AdaBoostClassifier, \\\n",
        "     GradientBoostingClassifier, \\\n",
        "     ExtraTreesClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, \\\n",
        "     log_loss, \\\n",
        "     classification_report, \\\n",
        "     confusion_matrix, \\\n",
        "     roc_auc_score,\\\n",
        "     average_precision_score,\\\n",
        "     auc,\\\n",
        "     roc_curve, f1_score, recall_score, matthews_corrcoef, auc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "Names = ['SVM', 'RF', 'ET', 'XGB', 'KNN', 'DT', 'NB', 'AB']\n",
        "Classifiers = [\n",
        "    SVC(probability=True),                  #1\n",
        "    RandomForestClassifier(),               #2\n",
        "    ExtraTreesClassifier(),                 #3\n",
        "    xgb.XGBClassifier(),                    #4\n",
        "    KNeighborsClassifier(n_neighbors=5),    #5\n",
        "    DecisionTreeClassifier(),               #6\n",
        "    GaussianNB(),                           #7    \n",
        "    AdaBoostClassifier(),                   #8\n",
        "]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZJvMKeIOQIr"
      },
      "source": [
        "def classifiersCV(X, y):\n",
        "    Results = []\n",
        "    for classifier, name in zip(Classifiers, Names):\n",
        "        accuray = []\n",
        "        auROC = []\n",
        "        avePrecision = []\n",
        "        F1_Score = []\n",
        "        AUC = []\n",
        "        MCC = []\n",
        "        Recall = []\n",
        "        LogLoss = []\n",
        "\n",
        "        mean_TPR = 0.0\n",
        "        mean_FPR = np.linspace(0, 1, 100)\n",
        "\n",
        "        CM = np.array([\n",
        "            [0, 0],\n",
        "            [0, 0],\n",
        "        ], dtype=int)\n",
        "\n",
        "        # print('{} is done.'.format(classifier.__class__.__name__))\n",
        "        print(classifier.__class__.__name__+'\\n')\n",
        "\n",
        "        model = classifier\n",
        "        for (train_index, test_index) in cv.split(X, y):\n",
        "\n",
        "            X_train = X[train_index]\n",
        "            X_test = X[test_index]\n",
        "\n",
        "            y_train = y[train_index]\n",
        "            y_test = y[test_index]\n",
        "\n",
        "            # Step 06 : Scaling the feature\n",
        "            \n",
        "            scale = StandardScaler()\n",
        "            X_train = scale.fit_transform(X_train)\n",
        "            X_test = scale.transform(X_test)\n",
        "\n",
        "            # model = BaggingClassifier(classifier)\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # print(model.predict(X_train))\n",
        "\n",
        "            # Calculate ROC Curve and Area the Curve\n",
        "            y_proba = model.predict_proba(X_test)[:, 1]\n",
        "            FPR, TPR, _ = roc_curve(y_test, y_proba)\n",
        "            mean_TPR += np.interp(mean_FPR, FPR, TPR)\n",
        "            mean_TPR[0] = 0.0\n",
        "            roc_auc = auc(FPR, TPR)\n",
        "            ##########################################\n",
        "            # print(FPR)\n",
        "            # print(TPR)\n",
        "            ##########################################\n",
        "\n",
        "            y_artificial = model.predict(X_test)\n",
        "\n",
        "            auROC.append(roc_auc_score(y_true=y_test, y_score=y_proba))\n",
        "\n",
        "            accuray.append(accuracy_score(y_pred=y_artificial, y_true=y_test))\n",
        "            avePrecision.append(average_precision_score(y_true=y_test, y_score=y_proba)) # auPR\n",
        "            F1_Score.append(f1_score(y_true=y_test, y_pred=y_artificial))\n",
        "            MCC.append(matthews_corrcoef(y_true=y_test, y_pred=y_artificial))\n",
        "            Recall.append(recall_score(y_true=y_test, y_pred=y_artificial))\n",
        "            AUC.append(roc_auc)\n",
        "\n",
        "            CM += confusion_matrix(y_pred=y_artificial, y_true=y_test)\n",
        "\n",
        "        accuray = [_*100.0 for _ in accuray]\n",
        "        Results.append(accuray)\n",
        "\n",
        "        mean_TPR /= cv.get_n_splits(X, y)\n",
        "        mean_TPR[-1] = 1.0\n",
        "        mean_auc = auc(mean_FPR, mean_TPR)\n",
        "\n",
        "        print('Accuracy: {0:.2f}'.format(np.mean(Results)))\n",
        "        # print('auROC: {0:.6f}'.format(np.mean(auROC)))\n",
        "        # print('auROC: {0:.4f}\\n'.format(mean_auc))\n",
        "        # F.write('AUC: {0:.4f}\\n'.format( np.mean(AUC)))\n",
        "        # print('auPR: {0:.4f}'.format(np.mean(avePrecision))) # average_Precision\n",
        "        # print('F1_Score: {0:.4f}\\n'.format(np.mean(F1_Score)))\n",
        "        \n",
        "\n",
        "        TN, FP, FN, TP = CM.ravel()\n",
        "        # print('Recall: {0:.4f}\\n'.format( np.mean(Recall)) )\n",
        "        print('Sensitivity: {0:.2f}'.format( ((TP) / (TP + FN))*100.0 ))\n",
        "        print('Specificity: {0:.2f}'.format( ((TN) / (TN + FP))*100.0 ))\n",
        "        print('MCC: {0:.2f}'.format(np.mean(MCC)))\n",
        "        # print('Confusion Matrix:\\n')\n",
        "        # print(str(CM)+'\\n')\n",
        "\n",
        "        print('{:.2f} {:.2f} {:.2f} {:.2f}'.format(np.mean(Results), ((TP) / (TP + FN))*100.0, ((TN) / (TN + FP))*100.0, np.mean(MCC)))\n",
        "        print('_______________________________________'+'\\n')\n",
        "#end-def"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb96LvofPu6w",
        "outputId": "674be0c2-5f62-4f17-9fd2-8e2a4170c5b0"
      },
      "source": [
        "X = d240bpf\n",
        "Y = d240y\n",
        "\n",
        "classifiersCV(X, Y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC\n",
            "\n",
            "Accuracy: 70.00\n",
            "Sensitivity: 62.02\n",
            "Specificity: 79.28\n",
            "MCC: 0.42\n",
            "70.00 62.02 79.28 0.42\n",
            "_______________________________________\n",
            "\n",
            "RandomForestClassifier\n",
            "\n",
            "Accuracy: 73.96\n",
            "Sensitivity: 79.07\n",
            "Specificity: 76.58\n",
            "MCC: 0.56\n",
            "73.96 79.07 76.58 0.56\n",
            "_______________________________________\n",
            "\n",
            "ExtraTreesClassifier\n",
            "\n",
            "Accuracy: 73.61\n",
            "Sensitivity: 73.64\n",
            "Specificity: 72.07\n",
            "MCC: 0.46\n",
            "73.61 73.64 72.07 0.46\n",
            "_______________________________________\n",
            "\n",
            "XGBClassifier\n",
            "\n",
            "Accuracy: 75.21\n",
            "Sensitivity: 78.29\n",
            "Specificity: 81.98\n",
            "MCC: 0.60\n",
            "75.21 78.29 81.98 0.60\n",
            "_______________________________________\n",
            "\n",
            "KNeighborsClassifier\n",
            "\n",
            "Accuracy: 71.25\n",
            "Sensitivity: 98.45\n",
            "Specificity: 5.41\n",
            "MCC: 0.06\n",
            "71.25 98.45 5.41 0.06\n",
            "_______________________________________\n",
            "\n",
            "DecisionTreeClassifier\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 72.99\n",
            "Sensitivity: 80.62\n",
            "Specificity: 82.88\n",
            "MCC: 0.64\n",
            "72.99 80.62 82.88 0.64\n",
            "_______________________________________\n",
            "\n",
            "GaussianNB\n",
            "\n",
            "Accuracy: 72.44\n",
            "Sensitivity: 75.97\n",
            "Specificity: 61.26\n",
            "MCC: 0.38\n",
            "72.44 75.97 61.26 0.38\n",
            "_______________________________________\n",
            "\n",
            "AdaBoostClassifier\n",
            "\n",
            "Accuracy: 72.86\n",
            "Sensitivity: 78.29\n",
            "Specificity: 72.97\n",
            "MCC: 0.52\n",
            "72.86 78.29 72.97 0.52\n",
            "_______________________________________\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p69CwjMUb8x"
      },
      "source": [
        "def classifiersTT(X_train, y_train, X_test, y_test):\n",
        "    for classifier, name in zip(Classifiers, Names):\n",
        "        \n",
        "        CM = np.array([\n",
        "            [0, 0],\n",
        "            [0, 0],\n",
        "        ], dtype=int)\n",
        "\n",
        "        # print('{} is done.'.format(classifier.__class__.__name__))\n",
        "        print(classifier.__class__.__name__+'\\n')\n",
        "\n",
        "        model = classifier\n",
        "        # Step 06 : Scaling the feature\n",
        "        \n",
        "        scale = StandardScaler()\n",
        "        X_train = scale.fit_transform(X_train)\n",
        "        X_test = scale.transform(X_test)\n",
        "\n",
        "        # model = BaggingClassifier(classifier)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # print(model.predict(X_train))\n",
        "\n",
        "        # Calculate ROC Curve and Area the Curve\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "        FPR, TPR, _ = roc_curve(y_test, y_proba)\n",
        "        # mean_TPR += np.interp(mean_FPR, FPR, TPR)\n",
        "        # mean_TPR[0] = 0.0\n",
        "        roc_auc = auc(FPR, TPR)\n",
        "        ##########################################\n",
        "        # print(FPR)\n",
        "        # print(TPR)\n",
        "        ##########################################\n",
        "\n",
        "        y_artificial = model.predict(X_test)\n",
        "\n",
        "        auROC = roc_auc_score(y_true=y_test, y_score=y_proba)\n",
        "\n",
        "        accuracy = accuracy_score(y_pred=y_artificial, y_true=y_test)\n",
        "        \n",
        "        MCC = matthews_corrcoef(y_true=y_test, y_pred=y_artificial)\n",
        "\n",
        "        CM = confusion_matrix(y_pred=y_artificial, y_true=y_test)\n",
        "\n",
        "        print('Accuracy: {0:.2f}'.format(accuracy))\n",
        "        # print('auROC: {0:.6f}'.format(np.mean(auROC)))\n",
        "        # print('auROC: {0:.4f}\\n'.format(mean_auc))\n",
        "        # F.write('AUC: {0:.4f}\\n'.format( np.mean(AUC)))\n",
        "        # print('auPR: {0:.4f}'.format(np.mean(avePrecision))) # average_Precision\n",
        "        # print('F1_Score: {0:.4f}\\n'.format(np.mean(F1_Score)))\n",
        "        \n",
        "\n",
        "        TN, FP, FN, TP = CM.ravel()\n",
        "        # print('Recall: {0:.4f}\\n'.format( np.mean(Recall)) )\n",
        "        print('Sensitivity: {0:.2f}'.format( ((TP) / (TP + FN))*100.0 ))\n",
        "        print('Specificity: {0:.2f}'.format( ((TN) / (TN + FP))*100.0 ))\n",
        "        print('MCC: {0:.2f}'.format(MCC))\n",
        "        # print('Confusion Matrix:\\n')\n",
        "        # print(str(CM)+'\\n')\n",
        "        print('{:.2f} {:.2f} {:.2f} {:.2f}'.format(accuracy*100, ((TP) / (TP + FN))*100.0, ((TN) / (TN + FP))*100.0, MCC))\n",
        "        print('_______________________________________'+'\\n')\n",
        "#end-def"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8pfFpSCYr5r",
        "outputId": "171dca8c-7afc-4986-a8c2-29f49ccf2a77"
      },
      "source": [
        "Xtrain = d500blo62\n",
        "Ytrain = d500ytrain\n",
        "\n",
        "Xtest = d164blo62\n",
        "Ytest = d164ytest\n",
        "\n",
        "classifiersTT(Xtrain, Ytrain, Xtest, Ytest)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC\n",
            "\n",
            "Accuracy: 0.78\n",
            "Sensitivity: 82.93\n",
            "Specificity: 73.17\n",
            "MCC: 0.56\n",
            "78.05 82.93 73.17 0.56\n",
            "_______________________________________\n",
            "\n",
            "RandomForestClassifier\n",
            "\n",
            "Accuracy: 0.85\n",
            "Sensitivity: 86.59\n",
            "Specificity: 84.15\n",
            "MCC: 0.71\n",
            "85.37 86.59 84.15 0.71\n",
            "_______________________________________\n",
            "\n",
            "ExtraTreesClassifier\n",
            "\n",
            "Accuracy: 0.85\n",
            "Sensitivity: 84.15\n",
            "Specificity: 85.37\n",
            "MCC: 0.70\n",
            "84.76 84.15 85.37 0.70\n",
            "_______________________________________\n",
            "\n",
            "XGBClassifier\n",
            "\n",
            "Accuracy: 0.83\n",
            "Sensitivity: 84.15\n",
            "Specificity: 81.71\n",
            "MCC: 0.66\n",
            "82.93 84.15 81.71 0.66\n",
            "_______________________________________\n",
            "\n",
            "KNeighborsClassifier\n",
            "\n",
            "Accuracy: 0.67\n",
            "Sensitivity: 45.12\n",
            "Specificity: 89.02\n",
            "MCC: 0.38\n",
            "67.07 45.12 89.02 0.38\n",
            "_______________________________________\n",
            "\n",
            "DecisionTreeClassifier\n",
            "\n",
            "Accuracy: 0.82\n",
            "Sensitivity: 80.49\n",
            "Specificity: 82.93\n",
            "MCC: 0.63\n",
            "81.71 80.49 82.93 0.63\n",
            "_______________________________________\n",
            "\n",
            "GaussianNB\n",
            "\n",
            "Accuracy: 0.69\n",
            "Sensitivity: 69.51\n",
            "Specificity: 68.29\n",
            "MCC: 0.38\n",
            "68.90 69.51 68.29 0.38\n",
            "_______________________________________\n",
            "\n",
            "AdaBoostClassifier\n",
            "\n",
            "Accuracy: 0.79\n",
            "Sensitivity: 78.05\n",
            "Specificity: 79.27\n",
            "MCC: 0.57\n",
            "78.66 78.05 79.27 0.57\n",
            "_______________________________________\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbPVwfOYZmUA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}